Project file structure:
=======================
./
    app.ts
    brain.ts
    server.ts
    middleware/
        errorHandler.ts
    types/
        tree-sitter-typescript.d.ts
    core/
        chunker.ts
    scripts/
        ingest.ts
    api/
        tasks/
            task.controller.ts
            task.routes.ts
            task.service.ts
        projects/
            project.controller.ts
            project.routes.ts
            project.service.ts
            qa.service.ts
    services/
        db.ts
        git.ts
        openai.ts


File Contents:
===============


--- FILE: app.ts ---

// src/app.ts
import 'dotenv/config';
import express from 'express';
import path from 'path';
import projectRoutes from './api/projects/project.routes';
import cors from 'cors';
import { errorHandler } from './middleware/errorHandler';

const app = express();
app.use(cors());

// Middleware
app.use(express.json());
app.use(express.static(path.join(process.cwd(), 'public')));

// API Routes
app.use('/api/projects', projectRoutes);

// Error Handler
app.use(errorHandler);

export default app;

--- FILE: brain.ts ---

#!/usr/bin/env node
// --- FILE: brain.ts ---

import 'dotenv/config';
import { Command } from 'commander';
import { Client } from 'pg';
import pgvector from 'pgvector/pg';
import OpenAI from 'openai';
import { runIngestion } from './scripts/ingest';
import simpleGit, { SimpleGit } from 'simple-git';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';

// --- CONFIGURATION ---
const connectionString = process.env.DATABASE_URL!;
const openaiApiKey = process.env.OPENAI_API_KEY!;
const WORKSPACE_DIR = path.join(os.homedir(), '.ai-brain-workspace');

if (!connectionString || !openaiApiKey) {
    throw new Error("FATAL: Missing environment variables DATABASE_URL or OPENAI_API_KEY");
}
const openai = new OpenAI({ apiKey: openaiApiKey });
const program = new Command();

// --- HELPER FUNCTIONS ---

/**
 * Retrieves the ID for a project from the database based on its source (Git URL or path).
 * If the project doesn't exist, it creates a new one.
 * @param source The unique Git URL or local path for the project.
 * @param client The active Postgres client.
 * @returns The numeric ID of the project.
 */
async function getProjectId(source: string, client: Client): Promise<number> {
    const projectRes = await client.query('SELECT id FROM projects WHERE source = $1', [source]);
    if (projectRes.rows.length > 0) {
        return projectRes.rows[0].id;
    } else {
        const projectName = path.basename(source, path.extname(source));
        console.log(`‚ú® Creating new project entry for '${projectName}'...`);
        const newProjectRes = await client.query(
            'INSERT INTO projects (name, source) VALUES ($1, $2) RETURNING id',
            [projectName, source]
        );
        return newProjectRes.rows[0].id;
    }
}

async function getEmbedding(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text.replace(/\n/g, ' '),
  });
  return response.data[0].embedding;
}

function getWorkspacePathFromUrl(url: string): string {
    try {
        const parsedUrl = new URL(url);
        const cleanPath = (parsedUrl.hostname + parsedUrl.pathname).replace(/\.git$/, '');
        return path.join(WORKSPACE_DIR, cleanPath);
    } catch (e) {
        const sshMatch = url.match(/git@([^:]+):(.*)/);
        if (sshMatch) {
            const host = sshMatch[1];
            const repoPath = sshMatch[2].replace(/\.git$/, '');
            return path.join(WORKSPACE_DIR, host, repoPath);
        }
        return path.join(WORKSPACE_DIR, url.replace(/[^a-zA-Z0-9]/g, '_'));
    }
}

// --- CLI COMMAND DEFINITIONS ---

program
  .command('ingest')
  .description('Ingest a project from a local path or a public Git URL.')
  .argument('<source>', 'The local path or Git URL of the project')
  .action(async (source: string) => {
    let projectPath = source;

    if (source.startsWith('http') || source.startsWith('git@')) {
        projectPath = getWorkspacePathFromUrl(source);
        try {
            await fs.mkdir(WORKSPACE_DIR, { recursive: true });
            try {
                await fs.access(path.join(projectPath, '.git'));
                console.log(`üß† Found existing repository. Fetching updates from ${source}...`);
                await simpleGit(projectPath).pull();
                console.log(`   -> Updates pulled successfully.`);
            } catch (error) {
                console.log(`üß† Cloning repository from ${source}...`);
                await simpleGit().clone(source, projectPath);
                console.log(`   -> Cloned successfully into: ${projectPath}`);
            }
        } catch (gitError) {
            console.error('‚ùå A Git error occurred:', gitError);
            process.exit(1);
        }
    }

    const client = new Client({ connectionString });
    try {
      await client.connect();
      const projectId = await getProjectId(source, client);
      await runIngestion(projectId, projectPath, console.log);
      console.log('‚úÖ Ingestion complete.');
    } catch (error) {
      console.error('‚ùå Ingestion failed:', error);
      process.exit(1);
    } finally {
      await client.end();
    }
  });

program
  .command('ask')
  .description('Ask a question about the indexed codebase.')
  .argument('<question>', 'The question to ask')
  .requiredOption('-p, --project <source>', 'The project source (Git URL or local path)')
  .action(async (question: string, options: { project: string }) => {
    console.log(`üß† Thinking about: "${question}"`);
    const client = new Client({ connectionString });
    try {
      await client.connect();
      await pgvector.registerType(client);
      const projectId = await getProjectId(options.project, client);

      const questionEmbedding = await getEmbedding(question);
      let contextString = '';

      // --- Retrieve relevant tasks ---
      const { rows: relevantTasks } = await client.query(
        `SELECT task_number, title, status FROM tasks WHERE project_id = $1 ORDER BY embedding <=> $2 LIMIT 3`,
        [projectId, pgvector.toSql(questionEmbedding)]
      );

      if (relevantTasks.length > 0) {
        console.log(`\nüîç Found relevant tasks: ${relevantTasks.map(t => `#${t.task_number}`).join(', ')}`);
        contextString += "Relevant Tasks:\n" + relevantTasks.map(t => `- Task #${t.task_number} [${t.status.toUpperCase()}]: ${t.title}`).join('\n') + '\n\n';
      }

      // --- Retrieve relevant commits ---
      const { rows: relevantCommits } = await client.query(
        `SELECT commit_hash, message, author_name FROM commits WHERE project_id = $1 ORDER BY embedding <=> $2 LIMIT 3`,
        [projectId, pgvector.toSql(questionEmbedding)]
      );
      
      if (relevantCommits.length > 0) {
          console.log(`\nüîç Found relevant commits: ${relevantCommits.map(c => c.commit_hash.substring(0, 7)).join(', ')}`);
          contextString += "Relevant Commits:\n" + relevantCommits.map(c => `- Commit ${c.commit_hash.substring(0, 7)} by ${c.author_name}: ${c.message.split('\n')[0]}`).join('\n') + '\n\n';
      }

      // --- Retrieve relevant files and code chunks ---
      const { rows: relevantFiles } = await client.query(
        `SELECT id, path, summary FROM indexed_files WHERE project_id = $1 ORDER BY summary_embedding <=> $2 LIMIT 5`,
        [projectId, pgvector.toSql(questionEmbedding)]
      );
      
      if (relevantFiles.length === 0 && relevantTasks.length === 0 && relevantCommits.length === 0) {
        console.log("I couldn't find any relevant information to answer that question.");
        return;
      }
      
      if (relevantFiles.length > 0) {
        console.log(`\nüîç Found relevant files: ${relevantFiles.map(f => f.path).join(', ')}`);
        const relevantFileIds = relevantFiles.map(f => f.id);

        const { rows: contextChunks } = await client.query(
          `SELECT file_id, content, chunk_name FROM code_chunks WHERE file_id = ANY($1::int[]) ORDER BY embedding <=> $2 LIMIT 10`,
          [relevantFileIds, pgvector.toSql(questionEmbedding)]
        );

        if (contextChunks.length > 0) {
          const chunkContext = contextChunks.map(c => {
            const filePath = relevantFiles.find(f => f.id === c.file_id)?.path;
            return `--- FILE: ${filePath} (Chunk: ${c.chunk_name}) ---\n\n${c.content}`;
          }).join('\n\n');
          contextString += "Relevant Code Snippets:\n" + chunkContext;
        }
      }

      if (!contextString.trim()) {
        console.log("I found some potentially relevant items but couldn't construct a concrete context to answer your question.");
        return;
      }

      const systemPrompt = `You are an expert AI software engineer. Answer the user's question based ONLY on the provided context, which may include tasks, commits, and code snippets. Be concise, accurate, and provide code snippets in Markdown format when relevant. If the context is insufficient, state that clearly.`;
      const userPrompt = `CONTEXT:\n${contextString}\n\nQUESTION:\n${question}`;

      const stream = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [{ role: 'system', content: systemPrompt }, { role: 'user', content: userPrompt }],
        stream: true,
      });
      
      console.log('\nüí¨ Answer:\n');
      for await (const chunk of stream) {
        process.stdout.write(chunk.choices[0]?.delta?.content || '');
      }
      console.log('\n');

    } catch (error) {
      console.error('‚ùå An error occurred:', error);
    } finally {
      await client.end();
    }
  });

// --- TASK MANAGEMENT COMMANDS ---
const task = program.command('task').description('Manage project tasks');

task
  .command('add')
  .description('Add a new task to a project')
  .argument('<title>', 'The title of the task')
  .requiredOption('-p, --project <source>', 'The project source (Git URL or local path)')
  .action(async (title: string, options: { project: string }) => {
    const client = new Client({ connectionString });
    try {
        await client.connect();
        const projectId = await getProjectId(options.project, client);
        
        const titleEmbedding = await getEmbedding(title);

        const result = await client.query(
            'INSERT INTO tasks (project_id, title, embedding) VALUES ($1, $2, $3) RETURNING task_number',
            [projectId, title, pgvector.toSql(titleEmbedding)]
        );
        const taskNumber = result.rows[0].task_number;
        console.log(`‚úÖ Created task #${taskNumber}: "${title}"`);
    } catch (error) {
        console.error('‚ùå Could not add task:', error);
        console.error('NOTE: This might be due to a missing `embedding` column on the `tasks` table. Please run: ALTER TABLE tasks ADD COLUMN embedding vector(1536);');
    } finally {
        await client.end();
    }
  });

task
  .command('list')
  .description('List tasks for a project')
  .requiredOption('-p, --project <source>', 'The project source (Git URL or local path)')
  .option('--status <status>', 'Filter by status (e.g., open, done)', 'open')
  .action(async (options: { project: string, status: string }) => {
    const client = new Client({ connectionString });
    try {
        await client.connect();
        const projectId = await getProjectId(options.project, client);
        const { rows } = await client.query(
            'SELECT task_number, title, status FROM tasks WHERE project_id = $1 AND status = $2 ORDER BY task_number ASC',
            [projectId, options.status]
        );

        if (rows.length === 0) {
            console.log(`No '${options.status}' tasks found for project: ${options.project}`);
            return;
        }

        console.log(`\nTasks for project: ${options.project} [Status: ${options.status}]`);
        console.log('--------------------------------------------------');
        rows.forEach(t => {
            const status = `[${t.status.toUpperCase()}]`.padEnd(7);
            console.log(`#${t.task_number.toString().padEnd(4)} ${status} ${t.title}`);
        });
        console.log('--------------------------------------------------');
    } catch (error) {
        console.error('‚ùå Could not list tasks:', error);
    } finally {
        await client.end();
    }
  });

program.parse(process.argv);

--- FILE: server.ts ---

// src/server.ts
import app from './app';

const port = process.env.PORT || 3000;

app.listen(port, () => {
    console.log(`üß† AI Project Brain is listening at http://localhost:${port}`);
});

--- FILE: middleware/errorHandler.ts ---

// src/middleware/errorHandler.ts
import { Request, Response, NextFunction } from 'express';

export function errorHandler(err: Error, req: Request, res: Response, next: NextFunction) {
    console.error(err.stack);
    res.status(500).json({ error: err.message || 'An internal server error occurred.' });
}

--- FILE: types/tree-sitter-typescript.d.ts ---

declare module 'tree-sitter-typescript/typescript';

--- FILE: core/chunker.ts ---

// --- FILE: core/chunker.ts ---
import Parser, { Query } from 'tree-sitter'; // MODIFIED: Import the Query class
import TypeScript from 'tree-sitter-typescript/typescript';

export interface CodeChunk {
  content: string;
  metadata: {
    type: 'function' | 'class' | 'method' | 'arrow_function' | 'block';
    name: string;
    start_line: number;
    end_line: number;
  };
}

const parser = new Parser();
parser.setLanguage(TypeScript);

// CRITICAL: This query identifies the distinct, semantic blocks of code.
const TS_QUERY = `
[
  (function_declaration) @chunk
  (class_declaration) @chunk
  (method_definition) @chunk
  (lexical_declaration 
    (variable_declarator 
      value: (arrow_function)
    )
  ) @chunk
]
`;

export function chunkCodeWithAST(content: string): CodeChunk[] {
  const tree = parser.parse(content);
  // MODIFIED: Use the Query constructor for robustness
  const query = new Query(TypeScript, TS_QUERY);
  const matches = query.captures(tree.rootNode);

  const chunks: CodeChunk[] = [];

  for (const match of matches) {
    const node = match.node;
    let name = 'anonymous';
    let type: CodeChunk['metadata']['type'] = 'block';

    // Heuristics to find the name of the chunk
    if (node.type === 'function_declaration' || node.type === 'class_declaration' || node.type === 'method_definition') {
        name = node.childForFieldName('name')?.text || 'anonymous';
        if (node.type === 'method_definition') type = 'method';
        else if (node.type === 'class_declaration') type = 'class';
        else type = 'function';
    } else if (node.type === 'lexical_declaration') {
        // For arrow functions like `const myFunc = () => ...`
        name = node.firstNamedChild?.firstNamedChild?.text || 'anonymous_arrow_function';
        type = 'arrow_function';
    }
    
    chunks.push({
      content: node.text,
      metadata: {
        type: type,
        name: name,
        start_line: node.startPosition.row + 1,
        end_line: node.endPosition.row + 1,
      },
    });
  }

  // Fallback: If no specific chunks were found (e.g., a simple config file),
  // treat the entire file as a single chunk.
  if (chunks.length === 0 && content.trim().length > 0) {
    chunks.push({
      content: content,
      metadata: {
        type: 'block',
        name: 'file_content',
        start_line: 1,
        end_line: content.split('\n').length,
      },
    });
  }

  return chunks;
}

--- FILE: scripts/ingest.ts ---

// --- FILE: scripts/ingest.ts ---

import 'dotenv/config';
import { glob } from 'glob';
import fs from 'fs';
import path from 'path';
import crypto from 'crypto';
import { Client } from 'pg';
import OpenAI from 'openai';
import gitignore from 'gitignore-parser';
import pgvector from 'pgvector/pg';
import { chunkCodeWithAST } from '../core/chunker';
import simpleGit, { SimpleGit } from 'simple-git';

// --- CONFIGURATION (Global) ---
const connectionString = process.env.DATABASE_URL!;
const openaiApiKey = process.env.OPENAI_API_KEY!;

if (!connectionString || !openaiApiKey) {
  throw new Error('FATAL: Missing environment variables DATABASE_URL or OPENAI_API_KEY');
}

const openai = new OpenAI({ apiKey: openaiApiKey });
const IGNORED_EXTENSIONS = new Set(['.lock', '.svg', '.png', '.jpg', '.jpeg', '.gif', '.ico']);
const IGNORED_FILENAMES = new Set(['package-lock.json', 'yarn.lock', 'pnpm-lock.yaml']);

// NEW: Define a logger type
export type IngestionLogger = (message: string) => void;

// --- CORE HELPER FUNCTIONS ---
async function getEmbedding(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text.replace(/\n/g, ' '),
  });
  return response.data[0].embedding;
}

async function summarizeFile(filePath: string, content: string, logger: IngestionLogger): Promise<string> {
  const prompt = `Summarize the purpose of the following code file in one sentence. File Path: ${filePath}\n\nCode:\n---\n${content}\n---\n\nOne-sentence summary:`;
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 100,
      temperature: 0.1,
    });
    return response.choices[0].message.content?.trim() || "Could not generate a summary.";
  } catch (error) {
    logger(`  - Failed to summarize ${filePath}: ${error instanceof Error ? error.message : String(error)}`);
    return "Summary generation failed.";
  }
}

// --- MAIN INGESTION LOGIC ---
export async function runIngestion(projectId: number, projectPath: string, logger: IngestionLogger) {
  const client = new Client({ connectionString });
  await client.connect();
  await pgvector.registerType(client);
  logger('Database connection established.');

  const git: SimpleGit = simpleGit(projectPath);

  try {
    await syncFiles(client, projectId, projectPath, logger);
    await syncGitHistory(client, projectId, git, logger);
  } finally {
    logger('Ingestion process finished. Closing database connection.');
    await client.end();
  }
}

// --- STAGE 1: Sync Filesystem State ---
async function syncFiles(client: Client, projectId: number, projectPath: string, logger: IngestionLogger) {
  logger(`[1/4] Starting file sync for project ID: ${projectId}`);
  
  logger(`[2/4] Pruning deleted files from the database...`);
  const { rows: dbFiles } = await client.query('SELECT path FROM indexed_files WHERE project_id = $1', [projectId]);
  const dbPaths = new Set(dbFiles.map(f => f.path));
  
  const allDiskFiles = await glob('**/*', { cwd: projectPath, nodir: true, dot: true, ignore: ['**/node_modules/**', '**/.git/**'] });
  const diskPaths = new Set(allDiskFiles);

  const pathsToDelete = [...dbPaths].filter(p => !diskPaths.has(p));

  if (pathsToDelete.length > 0) {
    logger(`      Found ${pathsToDelete.length} files to delete.`);
    await client.query('DELETE FROM indexed_files WHERE project_id = $1 AND path = ANY($2::text[])', [projectId, pathsToDelete]);
    logger(`      -> Pruning complete.`);
  } else {
    logger(`      -> No files to prune.`);
  }

  const gitignorePath = path.join(projectPath, '.gitignore');
  const ignore = fs.existsSync(gitignorePath)
    ? gitignore.compile(fs.readFileSync(gitignorePath, 'utf8'))
    : { accepts: (_p: string) => true };

  const filesToIndex = allDiskFiles.filter(file => {
    const ext = path.extname(file);
    const filename = path.basename(file);
    return ignore.accepts(file) && !IGNORED_EXTENSIONS.has(ext) && !IGNORED_FILENAMES.has(filename);
  });

  logger(`[3/4] Found ${filesToIndex.length} files to process for additions/modifications.`);
  let processedCount = 0;

  for (const relativePath of filesToIndex) {
    const fullPath = path.join(projectPath, relativePath);
    const content = fs.readFileSync(fullPath, 'utf-8');
    if (!content.trim()) continue;

    const hash = crypto.createHash('sha256').update(content).digest('hex'); // Corrected from sha265
    const { rows } = await client.query('SELECT content_hash FROM indexed_files WHERE project_id = $1 AND path = $2', [projectId, relativePath]);

    if (rows.length > 0 && rows[0].content_hash === hash) {
      continue;
    }

    processedCount++;
    logger(`      Processing changed file: ${relativePath}`);

    await client.query('BEGIN');
    try {
      await client.query('DELETE FROM indexed_files WHERE project_id = $1 AND path = $2', [projectId, relativePath]);
      
      const summary = await summarizeFile(relativePath, content, logger);
      const summaryEmbedding = await getEmbedding(summary);
      
      const fileInsertResult = await client.query(
        'INSERT INTO indexed_files (project_id, path, content_hash, summary, summary_embedding, last_indexed_at) VALUES ($1, $2, $3, $4, $5, NOW()) RETURNING id',
        [projectId, relativePath, hash, summary, pgvector.toSql(summaryEmbedding)]
      );
      const fileId = fileInsertResult.rows[0].id;
      
      const chunks = chunkCodeWithAST(content);
      for (const chunk of chunks) {
        const chunkEmbedding = await getEmbedding(chunk.content);
        await client.query(
          `INSERT INTO code_chunks (file_id, chunk_name, chunk_type, content, start_line, end_line, embedding) VALUES ($1, $2, $3, $4, $5, $6, $7)`,
          [fileId, chunk.metadata.name, chunk.metadata.type, chunk.content, chunk.metadata.start_line, chunk.metadata.end_line, pgvector.toSql(chunkEmbedding)]
        );
      }
      await client.query('COMMIT');
    } catch (error) {
      await client.query('ROLLBACK');
      logger(`      Failed to process ${relativePath}: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  logger(`[4/4] File sync complete. Processed ${processedCount} new or changed files.`);
}

// --- STAGE 2: Sync Git Commit History ---
async function syncGitHistory(client: Client, projectId: number, git: SimpleGit, logger: IngestionLogger) {
    logger('\n[1/3] Starting Git history sync...');
    
    const { rows: existingCommits } = await client.query('SELECT commit_hash FROM commits WHERE project_id = $1', [projectId]);
    const existingHashes = new Set(existingCommits.map(c => c.commit_hash));
    logger(`[2/3] Found ${existingHashes.size} existing commits in the database.`);

    const log = await git.log();
    const allCommits = [...log.all].reverse();

    const newCommits = allCommits.filter(c => !existingHashes.has(c.hash));
    if (newCommits.length === 0) {
        logger('[3/3] Git history is already up-to-date.');
        return;
    }
    logger(`      Found ${newCommits.length} new commits to process.`);

    for (const commit of newCommits) {
        logger(`      Processing commit ${commit.hash.substring(0, 7)}: ${commit.message}`);
        
        await client.query('BEGIN');
        try {
            const messageEmbedding = await getEmbedding(commit.message);
            const commitInsertResult = await client.query(
                `INSERT INTO commits (project_id, commit_hash, author_name, author_email, commit_date, message, embedding) VALUES ($1, $2, $3, $4, $5, $6, $7) RETURNING id`,
                [projectId, commit.hash, commit.author_name, commit.author_email, commit.date, commit.message, pgvector.toSql(messageEmbedding)]
            );
            const commitId = commitInsertResult.rows[0].id;
            
            const diff = await git.show(['--name-status', '--pretty=format:', commit.hash]);
            const changedFiles = diff.split('\n').filter(line => line.trim());

            for (const line of changedFiles) {
                const parts = line.split('\t');
                if (parts.length < 2) continue;
                const change_type = parts[0].trim();
                const file_path = parts[1].trim();
                
                const { rows } = await client.query('SELECT id FROM indexed_files WHERE project_id = $1 AND path = $2', [projectId, file_path]);

                if (rows.length > 0) {
                    const fileId = rows[0].id;
                    await client.query(
                        `INSERT INTO commit_files (commit_id, file_id, change_type) VALUES ($1, $2, $3)`,
                        [commitId, fileId, change_type]
                    );
                }
            }

            // NEW: Check commit message for task-closing keywords
            const taskRegex = /(?:closes|fixes|resolves)\s+#(\d+)/gi;
            let match;
            while ((match = taskRegex.exec(commit.message)) !== null) {
                const taskNumber = parseInt(match[1], 10);
                logger(`      -> Found reference to close task #${taskNumber}.`);
                const updateResult = await client.query(
                    `UPDATE tasks SET status = 'done', updated_at = NOW() WHERE project_id = $1 AND task_number = $2 AND status != 'done'`,
                    [projectId, taskNumber]
                );
                if (updateResult.rowCount && updateResult.rowCount > 0) {
                    logger(`      ‚úÖ Automatically closed task #${taskNumber}.`);
                }
            }

            await client.query('COMMIT');
        } catch (error) {
            await client.query('ROLLBACK');
            logger(`      Failed to process commit ${commit.hash}: ${error instanceof Error ? error.message : String(error)}`);
        }
    }
    logger('[3/3] Git history sync complete.');
}

--- FILE: api/tasks/task.controller.ts ---

// src/api/tasks/task.controller.ts
import { Request, Response, NextFunction } from 'express';
import * as taskService from './task.service';

export async function listTasks(req: Request, res: Response, next: NextFunction) {
    try {
        const projectId = parseInt(req.params.projectId, 10);
        const status = req.query.status as string | undefined; // Allow undefined
        const tasks = await taskService.getTasks(projectId, status);
        res.json(tasks);
    } catch (error) {
        next(error);
    }
}

// ADD THIS FUNCTION
export async function createTask(req: Request, res: Response, next: NextFunction) {
    try {
        const projectId = parseInt(req.params.projectId, 10);
        const { title } = req.body;
        if (!title) {
            return res.status(400).json({ error: 'A "title" is required.' });
        }
        const newTask = await taskService.createTask(projectId, title);
        res.status(201).json(newTask);
    } catch (error) {
        next(error);
    }
}

// ADD THIS FUNCTION
export async function updateTask(req: Request, res: Response, next: NextFunction) {
    try {
        const { projectId, taskNumber } = req.params;
        const { status } = req.body;
        
        const updatedTask = await taskService.updateTask(
            parseInt(projectId, 10),
            parseInt(taskNumber, 10),
            status
        );
        res.json(updatedTask);
    } catch (error) {
        next(error);
    }
}

--- FILE: api/tasks/task.routes.ts ---

// src/api/tasks/task.routes.ts
import { Router } from 'express';
import * as taskController from './task.controller';

const router = Router({ mergeParams: true }); // mergeParams is crucial for nested routes

router.get('/', taskController.listTasks);
router.post('/', taskController.createTask); 
router.put('/:taskNumber', taskController.updateTask); 

export default router;

--- FILE: api/tasks/task.service.ts ---

// src/api/tasks/task.service.ts
import { getDbClient } from '../../services/db';
import { getEmbedding } from '../../services/openai';
import pgvector from 'pgvector/pg';

export async function getTasks(projectId: number, status?: string) {
    const client = await getDbClient();
    try {
        let query = 'SELECT * FROM tasks WHERE project_id = $1';
        const params: any[] = [projectId];
        if (status) {
            query += ' AND status = $2';
            params.push(status);
        }
        query += ' ORDER BY task_number ASC';
        const { rows } = await client.query(query, params);
        return rows;
    } finally {
        // Use client.release() if using a pool, or client.end() for single client
        await client.end();
    }
}

export async function createTask(projectId: number, title: string) {
    const client = await getDbClient();
    try {
        const titleEmbedding = await getEmbedding(title);
        const { rows } = await client.query(
            'INSERT INTO tasks (project_id, title, embedding) VALUES ($1, $2, $3) RETURNING *',
            [projectId, title, pgvector.toSql(titleEmbedding)]
        );
        return rows[0];
    } catch (error) {
        console.error('Task creation failed. Ensure the `tasks` table has an `embedding` column.');
        throw error;
    }
    finally {
        await client.end();
    }
}

export async function updateTask(projectId: number, taskNumber: number, status: string) {
    const client = await getDbClient();
    try {
        // Ensure status is a valid one to prevent SQL injection with invalid enum values
        if (!['open', 'in_progress', 'done'].includes(status)) {
            throw new Error('Invalid task status');
        }

        const { rows } = await client.query(
            `UPDATE tasks SET status = $1, updated_at = NOW() 
             WHERE project_id = $2 AND task_number = $3 
             RETURNING *`,
            [status, projectId, taskNumber]
        );
        if (rows.length === 0) {
            throw new Error('Task not found');
        }
        return rows[0];
    } finally {
        await client.end();
    }
}

--- FILE: api/projects/project.controller.ts ---

// src/api/projects/project.controller.ts
import { Request, Response, NextFunction } from 'express';
import * as projectService from './project.service';
import * as qaService from './qa.service';

export async function listProjects(req: Request, res: Response, next: NextFunction) {
    try {
        const projects = await projectService.getAllProjects();
        res.json(projects);
    } catch (error) {
        next(error);
    }
}

export async function addProject(req: Request, res: Response, next: NextFunction) {
    try {
        const { source } = req.body;
        if (!source) {
            return res.status(400).json({ error: 'A "source" Git URL is required.' });
        }
        
        const { project, created } = await projectService.createProject(source);

        if (!created) {
            return res.status(200).json({ message: 'Project already exists.', project });
        }
        
        // Respond immediately and start ingestion in the background
        res.status(202).json({ message: 'Project created. Ingestion will start in the background.', project });
        projectService.startProjectIngestionInBackground(project.id, project.source);

    } catch (error) {
        next(error);
    }
}

// REMOVED old syncProject, which is replaced by streamIngestionLogs

// NEW: Controller for streaming ingestion logs
export async function streamIngestionLogs(req: Request, res: Response, next: NextFunction) {
    const projectId = parseInt(req.params.projectId, 10);
    
    // Set headers for SSE
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    res.flushHeaders(); // Flush the headers to establish the connection

    const logger = (message: string) => {
        // Format message for SSE
        res.write(`data: ${JSON.stringify({ log: message })}\n\n`);
    };

    // Handle client disconnect
    req.on('close', () => {
        console.log(`Client disconnected from ingestion stream for project ${projectId}.`);
        res.end();
    });

    try {
        const project = await projectService.getProjectById(projectId);
        if (!project) {
            logger(`Error: Project with ID ${projectId} not found.`);
            res.end();
            return;
        }
        
        // Start the ingestion and wait for it to complete, streaming logs along the way
        await projectService.startProjectIngestion(projectId, project.source, logger);
        
        // Signal the end of the stream
        res.write('event: end\ndata: {"message": "Ingestion complete"}\n\n');
        res.end();

    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        logger(`FATAL ERROR: ${errorMessage}`);
        console.error("Error during ingestion stream:", error);
        res.write(`event: error\ndata: {"message": "${errorMessage}"}\n\n`);
        res.end();
    }
}


export async function askQuestion(req: Request, res: Response, next: NextFunction) {
    try {
        const projectId = parseInt(req.params.projectId, 10);
        const { question } = req.body;
        if (!question) {
            return res.status(400).json({ error: 'A "question" is required.' });
        }
        
        const stream = await qaService.getAnswerStream(projectId, question);
        
        res.setHeader('Content-Type', 'text/plain; charset=utf-8');
        for await (const chunk of stream) {
            res.write(chunk.choices[0]?.delta?.content || '');
        }
        res.end();

    } catch (error) {
        if (!res.headersSent) {
          next(error);
        } else {
          console.error("Error during streaming:", error);
          res.end();
        }
    }
}

--- FILE: api/projects/project.routes.ts ---

// src/api/projects/project.routes.ts
import { Router } from 'express';
import * as projectController from './project.controller';
import taskRoutes from '../tasks/task.routes';

const router = Router();

router.get('/', projectController.listProjects);
router.post('/', projectController.addProject);

// MODIFIED: This is now a GET request to establish an SSE connection for logs
router.get('/:projectId/sync-stream', projectController.streamIngestionLogs);

router.post('/:projectId/ask', projectController.askQuestion);

// Mount task routes nested under projects
router.use('/:projectId/tasks', taskRoutes);

export default router;

--- FILE: api/projects/project.service.ts ---

// src/api/projects/project.service.ts
import { getDbClient } from '../../services/db';
import { cloneOrPullRepo } from '../../services/git';
import { runIngestion, IngestionLogger } from '../../scripts/ingest'; // Import IngestionLogger
import path from 'path';

export async function getAllProjects() {
    const client = await getDbClient();
    try {
        const { rows } = await client.query('SELECT id, name, source FROM projects ORDER BY created_at DESC');
        return rows;
    } finally {
        await client.end();
    }
}

export async function getProjectById(projectId: number) {
    const client = await getDbClient();
    try {
        const { rows } = await client.query('SELECT * FROM projects WHERE id = $1', [projectId]);
        if (rows.length === 0) {
            return null;
        }
        return rows[0];
    } finally {
        await client.end();
    }
}


export async function createProject(source: string) {
    const client = await getDbClient();
    try {
        const existing = await client.query('SELECT * FROM projects WHERE source = $1', [source]);
        if (existing.rows.length > 0) {
            // Project already exists, return it
            return { project: existing.rows[0], created: false };
        }

        const projectName = path.basename(source, path.extname(source));
        const { rows } = await client.query(
            'INSERT INTO projects (name, source) VALUES ($1, $2) RETURNING *',
            [projectName, source]
        );
        return { project: rows[0], created: true };
    } finally {
        await client.end();
    }
}

// MODIFIED: This function now accepts a logger and is the core logic for ingestion.
export async function startProjectIngestion(projectId: number, source: string, logger: IngestionLogger) {
    try {
        const projectPath = await cloneOrPullRepo(source, logger); // Pass logger to git service
        logger(`[Project ${projectId}] Ingestion running...`);
        await runIngestion(projectId, projectPath, logger);
        logger(`‚úÖ [Project ${projectId}] Ingestion complete.`);
    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        logger(`‚ùå [Project ${projectId}] Ingestion failed: ${errorMessage}`);
        console.error(`‚ùå [Project ${projectId}] Ingestion failed:`, error);
    }
}

// NEW HELPER for fire-and-forget ingestion
export function startProjectIngestionInBackground(projectId: number, source: string) {
    // We don't await this, so it runs in the background.
    // Logs will go to the console.
    startProjectIngestion(projectId, source, console.log);
}

--- FILE: api/projects/qa.service.ts ---

// src/api/projects/qa.service.ts
import { getDbClient } from '../../services/db';
import * as openAI from '../../services/openai';
import pgvector from 'pgvector/pg';

export async function getAnswerStream(projectId: number, question: string) {
    const client = await getDbClient();
    try {
        const questionEmbedding = await openAI.getEmbedding(question);
        let contextString = '';

        // --- Retrieve relevant tasks ---
        const { rows: relevantTasks } = await client.query(
            `SELECT task_number, title, status FROM tasks WHERE project_id = $1 ORDER BY embedding <=> $2 LIMIT 3`,
            [projectId, pgvector.toSql(questionEmbedding)]
        );
        if (relevantTasks.length > 0) {
            contextString += "Relevant Tasks:\n" + relevantTasks.map(t => `- Task #${t.task_number} [${t.status.toUpperCase()}]: ${t.title}`).join('\n') + '\n\n';
        }

        // --- Retrieve relevant commits ---
        const { rows: relevantCommits } = await client.query(
            `SELECT commit_hash, message, author_name FROM commits WHERE project_id = $1 ORDER BY embedding <=> $2 LIMIT 3`,
            [projectId, pgvector.toSql(questionEmbedding)]
        );
        if (relevantCommits.length > 0) {
            contextString += "Relevant Commits:\n" + relevantCommits.map(c => `- Commit ${c.commit_hash.substring(0, 7)} by ${c.author_name}: ${c.message.split('\n')[0]}`).join('\n') + '\n\n';
        }


        // --- Retrieve relevant files and code chunks ---
        const { rows: relevantFiles } = await client.query(
            `SELECT id, path FROM indexed_files WHERE project_id = $1 ORDER BY summary_embedding <=> $2 LIMIT 5`,
            [projectId, pgvector.toSql(questionEmbedding)]
        );
        
        if (relevantFiles.length > 0) {
            const relevantFileIds = relevantFiles.map(f => f.id);
            const { rows: contextChunks } = await client.query(
                `SELECT file_id, content, chunk_name FROM code_chunks WHERE file_id = ANY($1::int[]) ORDER BY embedding <=> $2 LIMIT 10`,
                [relevantFileIds, pgvector.toSql(questionEmbedding)]
            );
            
            if (contextChunks.length > 0) {
                 const chunkContext = contextChunks.map(c => {
                    const filePath = relevantFiles.find(f => f.id === c.file_id)?.path;
                    return `--- FILE: ${filePath} (Chunk: ${c.chunk_name}) ---\n\n${c.content}`;
                }).join('\n\n');
                contextString += "Relevant Code Snippets:\n" + chunkContext;
            }
        }
        
        if (!contextString.trim()) {
            throw new Error("No relevant context found for this question (no tasks, commits, or code).");
        }


        const systemPrompt = `You are an expert AI software engineer. Answer the user's question based ONLY on the provided context, which may include tasks, commits, and code snippets. Be concise, accurate, and provide code snippets in Markdown format when relevant. If the context is insufficient, state that clearly.`;
        const userPrompt = `CONTEXT:\n${contextString}\n\nQUESTION:\n${question}`;
        
        return openAI.getChatCompletionStream(systemPrompt, userPrompt);

    } finally {
        await client.end();
    }
}

--- FILE: services/db.ts ---

// src/services/db.ts
import { Client } from 'pg';
import pgvector from 'pgvector/pg';

const connectionString = process.env.DATABASE_URL!;

export async function getDbClient(): Promise<Client> {
    const client = new Client({ connectionString });
    await client.connect();
    await pgvector.registerType(client);
    return client;
}

--- FILE: services/git.ts ---

// src/services/git.ts
import simpleGit from 'simple-git';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';

const WORKSPACE_DIR = path.join(os.homedir(), '.ai-brain-workspace');
// Optional: Define a logger type for clarity
type GitLogger = (message: string) => void;


export function getWorkspacePathFromUrl(url: string): string {
    try {
        const parsedUrl = new URL(url);
        const cleanPath = (parsedUrl.hostname + parsedUrl.pathname).replace(/\.git$/, '');
        return path.join(WORKSPACE_DIR, cleanPath);
    } catch (e) {
        const sshMatch = url.match(/git@([^:]+):(.*)/);
        if (sshMatch) {
            const host = sshMatch[1];
            const repoPath = sshMatch[2].replace(/\.git$/, '');
            return path.join(WORKSPACE_DIR, host, repoPath);
        }
        return path.join(WORKSPACE_DIR, url.replace(/[^a-zA-Z0-9]/g, '_'));
    }
}

export async function cloneOrPullRepo(source: string, logger: GitLogger = console.log): Promise<string> {
    const projectPath = getWorkspacePathFromUrl(source);
    await fs.mkdir(WORKSPACE_DIR, { recursive: true });

    try {
        await fs.access(path.join(projectPath, '.git'));
        logger(`Found existing repository. Fetching updates from ${source}...`);
        await simpleGit(projectPath).pull();
        logger(`-> Updates pulled successfully.`);
    } catch (error) {
        logger(`Cloning repository from ${source}...`);
        await simpleGit().clone(source, projectPath);
        logger(`-> Cloned successfully.`);
    }
    return projectPath;
}

--- FILE: services/openai.ts ---

// src/services/openai.ts
import OpenAI from 'openai';

const openaiApiKey = process.env.OPENAI_API_KEY!;
if (!openaiApiKey) {
    throw new Error("FATAL: Missing environment variable OPENAI_API_KEY");
}

const openai = new OpenAI({ apiKey: openaiApiKey });

export async function getEmbedding(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: 'text-embedding-3-small',
    input: text.replace(/\n/g, ' '),
  });
  return response.data[0].embedding;
}

export async function getChatCompletionStream(systemPrompt: string, userPrompt: string) {
    return openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [{ role: 'system', content: systemPrompt }, { role: 'user', content: userPrompt }],
        stream: true,
    });
}